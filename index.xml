<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R&#39;s Blog</title>
    <link>https://rainmoment.github.io/</link>
    <description>Recent content on R&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 06 Jul 2017 13:17:28 +0800</lastBuildDate>
    
	<atom:link href="https://rainmoment.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>非线性分类器</title>
      <link>https://rainmoment.github.io/post/non_linear_classifier/</link>
      <pubDate>Thu, 06 Jul 2017 13:17:28 +0800</pubDate>
      
      <guid>https://rainmoment.github.io/post/non_linear_classifier/</guid>
      <description>There are two ways to write error-free programs; only the third works. –Alan J. Perlis
 一、引言 前面的学习中，我们学习了有关线性分类器的相关知识，但是要知道，很多情况下我们并不能保证类别间的分类面是线性的（线性是最简单的情况），而且许多复杂问题中，可能采用非线性分类器更适合问题的解决。这里主要说明感知器和支持向量机两种分类器。
二、发展进程 我们回顾一下神经网络发展的历程。神经网络的发展历史曲折荡漾，既有被人捧上天的时刻，也有摔落在街头无人问津的时段，中间经历了数次大起大落。
从单层神经网络（感知器）开始，到包含一个隐藏层的两层神经网络，再到多层的深度神经网络，一共有三次兴起过程。详见下图。
上图中的顶点与谷底可以看作神经网络发展的高峰与低谷。图中的横轴是时间，以年为单位。纵轴是一个神经网络影响力的示意表示。如果把1949年Hebb模型提出到1958年的感知机诞生这个10年视为落下（没有兴起）的话，那么神经网络算是经历了“三起三落”这样一个过程。俗话说，天将降大任于斯人也，必先苦其心志，劳其筋骨。经历过如此多波折的神经网络能够在现阶段取得成功也可以被看做是磨砺的积累吧。
历史最大的好处是可以给现在做参考。科学的研究呈现螺旋形上升的过程，不可能一帆风顺。同时，这也给现在过分热衷深度学习与人工智能的人敲响警钟，因为这不是第一次人们因为神经网络而疯狂了。1958年到1969年，以及1985年到1995，这两个十年间人们对于神经网络以及人工智能的期待并不比现在低，可结果如何大家也能看的很清楚。
因此，冷静才是对待目前深度学习热潮的最好办法。如果因为深度学习火热，或者可以有“钱景”就一窝蜂的涌入，那么最终的受害人只能是自己。神经网络界已经两次有被人们捧上天了的境况，相信也对于捧得越高，摔得越惨这句话深有体会。因此，神经网络界的学者也必须给这股热潮浇上一盆水，不要让媒体以及投资家们过分的高看这门技术。很有可能，三十年河东，三十年河西，在几年后，神经网络就再次陷入谷底。根据上图的历史曲线图，这是很有可能的。
三、异或问题 人们在研究非线性不可分问题时，不需要考虑复杂情况。众所周知，异或布尔函数是该问题的典型例子。可以将布尔函数理解为分类任务，即根据输入的二进制数x= 的不同，输出为0或1，将x归为A(1)或B(0)两类中的一种，表1中给出XOR操作对应的真值表。
表1 XOR问题的真值表
​ 图1给出了类在空间中的位置。从图中明显看出，一条直线不能将这两类分离，而另外两种布尔函数，AND和OR，却是线性可分的。表2中列出了AND和OR操作对应的真值表，图2(a)和2(b)描述了在二维空间中各类的位置。图3给出了能够计算突触权的感知器，从而实现OR门（验证）。
表2 AND和OR问题的真值表
​ ​ 图1 类A和类B的问题
​ ​ 图2 类A和类B的AND和OR问题
​ ​ 图3 实现OR门的感知器
现在最重要的是先处理XOR问题，然后将该过程扩展为非线性可分的一般情况。这里从几何结构开始。
四、两层感知器 ​ 为了分离图1中的两类A和B，最初的想法是画两条直线，而不是一条直线。
​ 图4给出了两条可能的直线，以及其之间的区域。现在可以将这两类分离，类A在 g1(x)的右侧(+)，g2 (x)的左侧 (-)。与类B对应的区域在g1 (x)的左侧， g2(x)的右侧。现在要做的是分两个阶段对问题进行处理，第一阶段是计算特征向量x相对于每一条决策线的位置；第二阶段结合前一阶段的结果，确定x相对应这两条线的位置，也就是说，x在阴影区域或在阴影区域内。现在从不同的角度来看这一问题，这会使后续的推广更容易。
​ ​ 图4 在XOR问题中两层感知器实现的决策线
​ 表 3 XOR问题的两个计算阶段的真值表
​ 在计算的第一阶段，激活函数f(.)是具有电平0和1的阶跃函数。表3给出了各种不同输入情况下产生的y值，即输入向量x与两条决策线中任意一条的相对位置。换一个角度，第一阶段是计算输入向量x到新向量[y1,y2]的映射。第二阶段是基于转换数据实现决策，从图5可以明显看出，画出第三条线g(y)就可以了，该线可以通过第三个神经元来实现。换言之，第一阶段的映射将非线性可分问题转换为线性可分问题。图6给出了实现方法，三条线中的每一条都是由具有适当突触权的神经元实现的。由此生成的多层结构可以认为是感知器的扩展，将它称为两层感知器或两层前馈神经网络。第一层的两个神经元实现最后阶段的计算，并构成输出层。
​ 图5 在XOR问题中由第二层的神经元形成的决策线</description>
    </item>
    
  </channel>
</rss>